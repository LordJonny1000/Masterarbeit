{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-20T23:46:32.252883Z",
     "start_time": "2025-09-20T23:46:32.224742Z"
    }
   },
   "source": [
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class MultilingualEmbeddingExtractor:\n",
    "    def __init__(self, embeddings_path: str = \"data/numberbatch-19.08.txt\"):\n",
    "        self.embeddings_path = Path(embeddings_path)\n",
    "        self.conceptnet_base_url = \"http://api.conceptnet.io\"\n",
    "\n",
    "    def get_translations(self, word: str, source_lang: str = \"en\") -> Dict[str, str]:\n",
    "        url = f\"{self.conceptnet_base_url}/query?node=/c/{source_lang}/{word}&rel=/r/Synonym\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "        except (requests.RequestException, ValueError) as e:\n",
    "            print(f\"Error fetching translations: {e}\")\n",
    "            return {}\n",
    "\n",
    "        translations = {source_lang: word}\n",
    "        for edge in data.get('edges', []):\n",
    "            end_node = edge.get('end', {})\n",
    "            lang = end_node.get('language')\n",
    "            if lang and lang != source_lang:\n",
    "                translations[lang] = end_node.get('label', '')\n",
    "\n",
    "        return translations\n",
    "\n",
    "    def load_embeddings_for_words(self, translations: Dict[str, str]) -> Dict[Tuple[str, str], np.ndarray]:\n",
    "        embeddings = {}\n",
    "        translations_lower = {lang: word.lower() for lang, word in translations.items()}\n",
    "\n",
    "        if not self.embeddings_path.exists():\n",
    "            raise FileNotFoundError(f\"Embeddings file not found: {self.embeddings_path}\")\n",
    "\n",
    "        with open(self.embeddings_path, 'r', encoding='utf-8') as f:\n",
    "            next(f)\n",
    "\n",
    "            for line in tqdm(f, desc=\"Searching embeddings\", file=sys.stdout):\n",
    "                parts = line.rstrip().split(' ')\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "\n",
    "                entry = parts[0]\n",
    "                entry_parts = entry.split('/')\n",
    "\n",
    "                if len(entry_parts) >= 4:\n",
    "                    target_lang = entry_parts[2]\n",
    "                    target_word = entry_parts[3].lower()\n",
    "\n",
    "                    if target_lang in translations_lower and translations_lower[target_lang] == target_word:\n",
    "                        vector = np.array([float(x) for x in parts[1:]], dtype=np.float32)\n",
    "                        embeddings[(target_lang, translations[target_lang])] = vector\n",
    "\n",
    "                        if len(embeddings) == len(translations):\n",
    "                            break\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def get_multilingual_embeddings(self, word: str, source_lang: str = \"en\") -> Dict[Tuple[str, str], np.ndarray]:\n",
    "        translations = self.get_translations(word, source_lang)\n",
    "        if not translations:\n",
    "            return {}\n",
    "\n",
    "        print(f\"Found translations for '{word}': {translations}\")\n",
    "        embeddings = self.load_embeddings_for_words(translations)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def analyze_embedding_consistency(embeddings: Dict[Tuple[str, str], np.ndarray]) -> Dict[str, float]:\n",
    "    if len(embeddings) < 2:\n",
    "        return {}\n",
    "\n",
    "    vectors = list(embeddings.values())\n",
    "    mean_vector = np.mean(vectors, axis=0)\n",
    "\n",
    "    consistencies = {}\n",
    "    for (lang, word), vector in embeddings.items():\n",
    "        cosine_sim = np.dot(vector, mean_vector) / (np.linalg.norm(vector) * np.linalg.norm(mean_vector))\n",
    "        consistencies[f\"{lang}:{word}\"] = float(cosine_sim)\n",
    "\n",
    "    return consistencies\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T23:47:06.927012Z",
     "start_time": "2025-09-20T23:47:02.399821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"hello\")\n",
    "\n",
    "\n",
    "extractor = MultilingualEmbeddingExtractor()\n",
    "word_list = ['sun', 'flower', 'heaven', 'hell', 'hello']\n",
    "for word in word_list:\n",
    "    \n",
    "    translations = extractor.get_translations(word)\n",
    "    print(translations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# print(f\"\\nFound {len(embeddings)} embeddings:\")\n",
    "# for (lang, word), vector in embeddings.items():\n",
    "#     print(f\"  {lang}: {word} - Vector shape: {vector}\")\n"
   ],
   "id": "fab0090c41a85a96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "{'en': 'sun', 'et': 'päike', 'sh': 'sunce', 'tg': 'офтоб', 'id': 'matahari'}\n",
      "{'en': 'flower', 'sh': 'cvijet'}\n",
      "{'en': 'heaven', 'sh': 'nebo', 'es': 'cielo'}\n",
      "{'en': 'hell', 'az': 'cəhənnəm', 'el': 'κολαση'}\n",
      "{'en': 'hello', 'sh': 'selam', 'fr': 'salut', 'es': 'hola'}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "336e0e51781aa8d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
